{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa15196d-c8db-4c30-8c08-086cd95ba4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a596b841-d575-4f8b-af3a-ba704bda7cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_preprocessing in c:\\users\\asus\\desktop\\academy\\it\\pyhon\\face emotion recognition\\.venv\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\asus\\desktop\\academy\\it\\pyhon\\face emotion recognition\\.venv\\lib\\site-packages (from keras_preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\desktop\\academy\\it\\pyhon\\face emotion recognition\\.venv\\lib\\site-packages (from keras_preprocessing) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf071c8-336a-4551-acde-69619e0776ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8bb952f-a787-4cc4-9392-8578a3ec9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR  =\"images/train\"\n",
    "TEST_DIR =\"images/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed0a4640-aab2-43bc-a9b9-be6351a429c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"complete\")\n",
    "    return image_paths, labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a9a3a3d-3ca5-42cb-a9de-2907458bc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this with your actual full path\n",
    "TRAIN_DIR = r\"C:\\Users\\ASUS\\Desktop\\Academy\\IT\\Pyhon\\Face Emotion Recognition\\archive\\images\\train\"\n",
    "\n",
    "# Test if directory exists\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(\"Directory does not exist!\")\n",
    "else:\n",
    "    train = pd.DataFrame()\n",
    "    train['image'], train['label'] = createdataframe(TRAIN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1bb65d-7d90-4560-94e5-0373b7d045f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0b97b-c916-483b-a540-b3addc07907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007858f-edcd-4ecf-8e7b-817562ebd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485d6d3-f3f0-472a-aad1-cad0c6f51d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d306f-c91b-4803-af56-e26d922dfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1116b-eb4e-4476-8b58-c1dcb5681abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afd19f-820d-4505-b9d9-f9f664536203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"Pillow\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074b2ab-4a8f-4d07-9393-b3c73af1368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "print(\"Pillow is installed and working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76d8c8-3a6a-42d2-8bb7-6dacf40a8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode='grayscale', target_size=(48, 48))  # updated\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d21d40-239a-4b18-9f7e-3db3e7f2bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python path:\", sys.executable)\n",
    "\n",
    "import os\n",
    "print(\"Directory listing:\")\n",
    "print(os.listdir(os.path.dirname(sys.executable)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d6fff-4a4a-4de0-aad5-8a50d42b113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!\"C:\\Users\\ASUS\\Desktop\\Academy\\IT\\Pyhon\\Face Emotion Recognition\\.venv\\Scripts\\python.exe\" -m pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f25e0-c2a4-439b-8c40-a1e4062d2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c988993-2724-4377-8444-ce612bac728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3afee-04cc-40c4-8d01-b471a75229b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dc92b-e711-41d8-9936-8d4a94bce1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8dd53-737e-4941-94c5-84ce45b957d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a308275-aba1-44db-b749-238a5ad2ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1406a-bc2c-4c06-b0c3-d991ff73b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4521f34-9d00-4c68-b45a-1e11cf8414a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5861b87-ed59-44d0-b03c-28baef723f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(48, 48, 1)),  # âœ… define input shape here\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328cc98-b0d0-494d-a4fd-1e6e7b5c1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])  \n",
    "test_features = extract_features(test['image']) \n",
    "predictions = model.predict(test_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57558a-b101-4298-9adc-dc3921ff7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e7ea60-a8a1-43b4-8a1e-86aa421b3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(48, 48, 1)))  # <-- define input here\n",
    "\n",
    "# Convolutional Layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8d1b3d-4179-422c-b4e9-75b844925fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d24955-99a9-4e64-8b88-aaf33a89eb03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'le' is not defined"
     ]
    }
   ],
   "source": [
    "y_test = le.transform(test['label'])\n",
    "y_test = to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d477516-41b8-4d58-9df2-8f22b3821a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aaf5832-bf0d-4b53-b16f-de64ee505961",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto_json()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotiondetector.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m      3\u001b[0m     json_file\u001b[38;5;241m.\u001b[39mwrite(model_json)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8e407-4c48-4847-9bad-db58a4a46bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75e99f-ab2f-43f9-b3e9-d98113e59f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6284d-255e-4cd1-a253-29e845e21b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
